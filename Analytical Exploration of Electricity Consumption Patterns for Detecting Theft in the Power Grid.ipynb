{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1cca5a0",
   "metadata": {},
   "source": [
    "# Set up the selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da9048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, make_scorer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9302f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"Data/data set.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea924b9b",
   "metadata": {},
   "source": [
    "## Rebuilding the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb9b203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a copy of the dataset\n",
    "df_index = df.copy()\n",
    "\n",
    "# Delete columns\n",
    "df_index.drop(['CONS_NO','10/3/2014'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4968109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove data from the majority class (FLAG = 0)\n",
    "df_clean = df_index.copy()\n",
    "df_minority = df_clean[df_clean['FLAG'] == 1]\n",
    "df_majority = df_clean[df_clean['FLAG'] == 0].sample(len(df_minority))\n",
    "df_undersampling = pd.concat([df_minority, df_majority]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ea3d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a copy of the dataset\n",
    "df_index = df_undersampling.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66ccdd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete columns\n",
    "df_index.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32e420a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a copy of the dataset\n",
    "df_filtered = df_index.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4d811c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the target column that has no null values to perform imputation\n",
    "df_filtered.drop(['FLAG'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d8ff884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7230, 1033)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute the data with respect to 5 neighbors\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputed = imputer.fit_transform(df_filtered)\n",
    "imputed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "102b34f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataset with the imputed data\n",
    "df_imputed = pd.DataFrame(imputed, columns=df_filtered.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ca8116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of the inputed dataset\n",
    "df_low = df_imputed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19509b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the FLAG column again\n",
    "df_low['FLAG'] = df_undersampling['FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4befe038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data from the label\n",
    "X = df_low.drop(['FLAG'], axis=1)\n",
    "y = df_low['FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fe5a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the training data from the testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596b166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Gradient Boosting\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid to explore\n",
    "param_grid = {'n_estimators': [50],'max_depth': [5],'min_samples_split': [2]}\n",
    "\n",
    "# Initialize the GridSearchCV object for Gradient Boosting\n",
    "grid_search_gb = GridSearchCV(estimator=gb, param_grid=param_grid, scoring='recall', cv=3, n_jobs=-1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = grid_search_gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272bab42",
   "metadata": {},
   "source": [
    "## Testing the model with the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0362773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a copy of the dataset\n",
    "df_full = df_clean.copy()\n",
    "\n",
    "# Delete columns\n",
    "df_full.drop(['CONS_NO','10/3/2014','FLAG'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7a9746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the data with respect to 5 neighbors\n",
    "imputer_full = KNNImputer(n_neighbors=5)\n",
    "imputed_full = imputer_full.fit_transform(df_full)\n",
    "imputed_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0a42a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataset with the imputed data\n",
    "df_imputed_full = pd.DataFrame(imputed_full, columns=df_full.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a88d2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of the inputed dataset\n",
    "df_index_full = df_imputed_full.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dccccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the FLAG column again\n",
    "df_index_full['FLAG'] = df_clean['FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4590a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data from the label\n",
    "X_full = df_index_full.drop(['FLAG'], axis=1)\n",
    "y_full = df_index_full['FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1051b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the training data from the testing data\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X_full, y_full, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9ef61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gb = grid_search_gb.predict(X_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e1ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the Gradient Boosting model with the best parameters\n",
    "accuracy_best_gb = accuracy_score(y_test_full, y_pred_gb)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "print(f\"Accuracy (Gradient Boosting - Best Parameters): {accuracy_best_gb:.2f}\")\n",
    "print(\"Classification Report (Gradient Boosting - Best Parameters):\")\n",
    "print(classification_report(y_test_full, y_pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d1ac8",
   "metadata": {},
   "source": [
    "### Future Work\n",
    "\n",
    "An intriguing observation reveals that addressing data imbalance with Undersampling instead of SMOTE (Synthetic Minority Over-sampling Technique) made a significant difference in the project's performance. Exploring alternative techniques to balance these imbalanced datasets would be worthwhile. Additionally, the dataset exhibits considerable variability in null values. Reducing the quantity of null data and imputing it with nearest neighbors significantly improved the model's performance. Considering alternative approaches, such as setting null values to zero, might also yield improved results.\n",
    "\n",
    "### Next steps and recommendations\n",
    "\n",
    "To delve deeper into this observation, several approaches can be taken. Firstly, investigating the origin of the numerous data gaps from the electric grid is essential. Null values may be attributed to various factors, such as a user recently joining the electric grid (resulting in no previous records), power outages, disconnections due to non-payment, etc. Handling these null values more delicately is crucial, as they significantly influence each user's consumption behavior. Additionally, another avenue to explore involves dividing the data into segments corresponding to electrical cutoff cycles, allowing for a more nuanced analysis of consumption patterns, alongside considering factors like billing cost and market electricity prices."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
